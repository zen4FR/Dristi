# DRISTI â€” AI-Based Assistive Vision System

**Semester project â€” Kathmandu University**

DRISTI helps visually impaired users understand their surroundings by converting an input **photo** into a spoken description using computer vision and lightweight transformer models.

---

## ðŸ”Ž Project Summary

- **Input:** single image (photo)  
- **Pipeline:** object detection (YOLOv8) â†’ depth estimation (MiDaS) â†’ image captioning (BLIP) â†’ fusion â†’ text-to-speech  
- **Output:** short spoken description + optional annotated image and JSON output  
- **Semester scope:** Photo-only MVP. Video/real-time will be implemented in a future semester.

---

## ðŸš€ Features

- Fast object detection with **YOLOv8**  
- Relative depth estimation using **MiDaS / DepthAnything**  
- Scene captioning via **BLIP** (Vision + Transformer)  
- Lightweight fusion engine (template-based NLG) â€” no large LLM required  
- Text-to-speech via **Coqui TTS** or system TTS  
- Modular code structure for easy extension

---

## ðŸ“ Repository Structure
dristi/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ detection/yolo_detector.py
â”‚ â”œâ”€â”€ depth/depth_estimator.py
â”‚ â”œâ”€â”€ captioning/caption_model.py
â”‚ â”œâ”€â”€ fusion/fuse.py
â”‚ â”œâ”€â”€ tts/speak.py
â”‚ â””â”€â”€ utils/image_utils.py
â”œâ”€â”€ models/ # (ignored in git) pretrained weights
â”œâ”€â”€ samples/
â”‚ â”œâ”€â”€ input/
â”‚ â””â”€â”€ output/
â”œâ”€â”€ docs/
â”‚ â””â”€â”€ architecture.md
â””â”€â”€ notebooks/


---

## âš™ï¸ Quick Setup

> Tested on Python 3.9+. Use a virtual environment.

```bash
# 1. Clone repository
git clone https://github.com/<your-username>/dristi.git
cd dristi

# 2. Create & activate venv
python -m venv venv
# Windows
venv\Scripts\activate
# Linux / macOS
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

Requirements (example):
ultralytics
torch
torchvision
opencv-python
transformers
timm
numpy
coqui-tts



ðŸ§  Design / Architecture

See docs/architecture.md for the full architecture description, data flow diagram, and deployment plan.
Short flow:
Image â†’ Preprocessing â†’ YOLOv8 â†’ MiDaS â†’ BLIP â†’ Fusion â†’ TTS â†’ Audio